#Basic NLP Processing

import nltk                                # Python library for NLP
from nltk.corpus import twitter_samples    # sample Twitter dataset from NLTK
import matplotlib.pyplot as plt            # library for visualization
import random                              # pseudo-random number generator


#Removing Stop Words and other unnecessary things

	1) nltk.download('stopwords')                 # download the stopwords from NLTK  
	2) Basic cleaning of removing hyperlinks and #
		import re                                  # library for regular expression operations
		import string                              # for string operations

		from nltk.corpus import stopwords          # module for stop words that come with NLTK
		from nltk.stem import PorterStemmer        # module for stemming
		from nltk.tokenize import TweetTokenizer   # module for tokenizing strings

		#sub function helps to remove the hyperlinks or replace some letters/ strings
		tweet2 = re.sub(r'https?://[^\s\n\r]+', '', tweet2)  #removes hyperlinks
		tweet2 = re.sub(r'#', '', tweet2)                    #removes hash

	3) Tokenize the Input text
		tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,reduce_len=True)     # instantiate tokenizer class
    	tweet_tokens = tokenizer.tokenize(tweet2)                                               #tweet_tokens will be tokenized

    4) remove stop words (in english) + remove punctuation

    	stopwords_english = stopwords.words('english') #list of stop words already in a list in english in nltk library

    	for word in tweet_tokens: # Go through every word in your tokens list
    		if (word not in stopwords_english and  # remove stopwords
    		word not in string.punctuation):  # remove punctuation
        		tweets_clean.append(word)
        #tweet_cleans is cleaned list of tokens


    #Stemming
    	1) stemmer = PorterStemmer()           # Instantiate stemming class
    	2) tweets_stem = [] 
    	3) for word in tweets_clean:
    			stem_word = stemmer.stem(word)  # stemming word
    			tweets_stem.append(stem_word)  # append to the list
 

