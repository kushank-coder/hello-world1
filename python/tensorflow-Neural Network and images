#importing tensorflow
import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
#the above image generator will directly extract the images from a folder which has sub folders (which forms the labels and the images inside)



#Defining Structure (one can add multiple layers before the })
model = tf.keras.Sequential([tf.keras.layers.Dense(units=64, input_shape=[150,150,3],activation = 'relu'),
                              tf.keras.layers.Dense(units=1,activation = 'sigmoid')              ])

#Defining the loss function type and optimizer (which makes the guess gives the direction to next guess)
model.compile(optimizer='sgd',loss='mean_squared_error')  # for multi class classification use "sparse_categorical_crossentropy"


#below is very important to visualize the model, its parameters requirements etc
model.summary()



#callbacks
class myCallback(tf.keras.callbacks.Callback):
    # Define the method that checks the accuracy at the end of each epoch
    def on_epoch_end(self, epoch, logs={}):
        if(logs.get('accuracy') >= 0.995): # Experiment with changing this value
            print("\nReached 60% accuracy so cancelling training!")
            self.model.stop_training = True


#Input for the neural network
xs = np.array([-1,0,1,2,3,4], dtype = float) #the dtype = float and numpy array
ys = np.array([-3,-1,1,3,5,7], dtype = float)


#Data from dataframe (reshape the dataset because tensorflow is shape sensitive)

#Y should be one dimensional(in our binary classification)
X_train = np.reshape(X_train,(455,30))
y_train = np.reshape(y_train,(455))


#convert them into numpy arrays with dtype = float
X_train2 = np.array(X_train, dtype = float)
y_train2 = np.array(y_train, dtype = float)


#fit the model

model.fit(x = X_train2, y =y_train2,epochs=500,callbacks=[callbacks])


#tensorflow takes numpy arrays as an input 
#without activation i believe the neural network will behave as a linear regression
model.predict([10])


### Visualize the image
#one needs to enter the complete array of a particular image to print the image 
plt.imshow(training_images[index])

#when we know the directory of image and path of image
plt.imshow(load_img(f"{os.path.join(train_horses_dir, os.listdir(train_horses_dir)[0])}"))      
plt.show()



####Convolution + Max Pooling layers

tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)), #3,3 is the filter , 32 filters are being executed, activation 																							over here is generally relu, input shape is important
tf.keras.layers.MaxPooling2D(2, 2),


# All images will be rescaled by 1./255
train_datagen = ImageDataGenerator(rescale=1/255, rotation_range=0.4,width_shift_range=0.4,height_shift_range=0.4,zoom_range=0.4) #except for rescale other parameters lead to data augmentation

# Flow training images in batches of 128 using train_datagen generator
train_generator = train_datagen.flow_from_directory( './horse-or-human/',  # This is the source directory for training images
        target_size=(300, 300),  # All images will be resized to 300x300 (vimp in real world scenarios)
        batch_size=128, #will define the steps_per_epoch
        # Since we use binary_crossentropy loss, we need binary labels otherwise use categorical
        class_mode='binary')

history = model.fit(
      train_generator,
      steps_per_epoch=8,  #steps per epoch * batch size must be equal to the length of our training dataset 
      epochs=15,
      verbose=1)


#evaluating the model on test dataset
results = model.evaluate(X_test, y_test)

#plotting training accuracy versus validation accuracy graphs (note before going down use history= model.fit())
#-----------------------------------------------------------
# Retrieve a list of list results on training and test data
# sets for each training epoch
#-----------------------------------------------------------
acc=history.history['accuracy']
val_acc=history.history['val_accuracy']
loss=history.history['loss']
val_loss=history.history['val_loss']

epochs=range(len(acc)) # Get number of epochs

#------------------------------------------------
# Plot training and validation accuracy per epoch
#------------------------------------------------
plt.plot(epochs, acc, 'r', "Training Accuracy")
plt.plot(epochs, val_acc, 'b', "Validation Accuracy")
plt.title('Training and validation accuracy')
plt.show()
print("")

#------------------------------------------------
# Plot training and validation loss per epoch
#------------------------------------------------
plt.plot(epochs, loss, 'r', "Training Loss")
plt.plot(epochs, val_loss, 'b', "Validation Loss")
plt.show()

### checking the shape of the image at a particular location
import cv2
 # Load the image
image = cv2.imread(r"C:\Users\hp\DATA SCIENCE\Practise Projects\CIFAR Dataset Kaggle\cifar-10\Class_wise_Images\training\airplane\30.png")
print(image.shape)  # this will give the shape of the image the 3rd axis gives the channel ie RGB Channel

####making directories/ folders in python

import os

os.makedirs(root_path)   # will make a directory , note last folder name will automatically will be the directory name

os.path.join(root_path,'train')  #this is a string concatenation (note train is not preceded by "/")


os.listdir(DIRECTORY) #returns a list with the contents of that directory.

os.path.getsize(PATH) #returns the size of the file # always use this code to check whether there is any corrupted image in the dataset

copyfile(source_path, destination_path) #copies a file from source to destination

random.sample(list, len(list)) #shuffles a list of items