#Pandas are equivalent to excel
### Creating a Series

You can convert a list,numpy array, or dictionary to a Series:

** Using Lists**

pd.Series(data=my_list)

# Converting NumPy Arrays into series

pd.Series(numpy_array)

#Dictionary gets easily converted into series.         

pd.Series(dictionary_name)                       

### Data in a Series

pd.Series(data=labels)

# Even functions (although unlikely that you will use this)
pd.Series([sum,print,len])

## Series can be easily accessible by the index (NO use of .loc required)

#Converts a Series data to dictionary data type
  s.to_dict()                                                     





# DataFrames

from numpy.random import randn
np.random.seed(101)

## NOTE: there is only one way to manually make a dataframe ie pd.DataFrame(data,indexes,column names)
##       other ways are we can import from csv in dataframe
NOTE : even dictionaries can be used to create dataframes in pandas ..the point is key in dictionary forms the column names and index is by default 0 1 etc.

## NOTE: we always need to use inplace = True  for actually bringing any change in the dataframe

# type of data object
type(df['W'])

** Removing Columns**

df.drop('new',axis=1)

# Not inplace unless specified!

df.drop('new',axis=1,inplace=True)                                            #inplace= True is must to actually edit the data frame "df"


#Accessing the rows and columns of data frame

df.loc['A']

Or select based off of position instead of label 

df.iloc[2]

### Conditional Selection

An important feature of pandas is conditional selection using bracket notation, very similar to numpy:

## Note : for conditional selection there is NO USE OF  ".iloc"  .we need to use iloc to slice the columns but conditional selection can be done directly and it filters the series of row values first. 
df

df[df>0]

df[df['W']>0]

For two conditions you can use | and & with parenthesis:

df[(df['W']>0) & (df['Y'] > 1)]                               #Note : If we use "and" operator it only takes 2 booleans only not a series of them ....whereas with "&" operator even a series of boleans can be compared
                                                                      same is true with "or" operator as well we need to use | for comparing series of booleans        
  ## More Index Details

Let's discuss some more features of indexing, including resetting the index or setting it something else. We'll also talk about index hierarchy!

df

# Reset to default 0,1...n index
df.reset_index()


# Missing Data
d = np.nan

df = pd.DataFrame({'A':[1,2,np.nan],
                  'B':[5,np.nan,np.nan],
                  'C':[1,2,3]})

#Dropping rows or columns from a dataframe

df.dropna()
df.fillna(value='FILL VALUE')

#Appending data frame 
  pd.concat([df,y])

#Group by
  df.groupby('Company')                 #"Company" is the name of the column by which we group by

# Joins
pd.merge(df1,df2,on = [lkey,rkey], suffixes=('_left', '_right')))             #suffixes removes the extra column-name name 

#unique method
df['col2'].unique()                                                            #gives distinct elements

# proc freq
df['col2'].value_counts()
 
 # using operations computing another column 
                                                                                #the column on which the operation is to be done is col1 .it is mentioned in the syntax
 df['col1'].apply(times2)                                                       #times 2 is the required function  
 
 # sorting
 df.sort_values(by='col2')                                                        #inplace=False by default....for sorting the data you need inplace =True
 
 #pivot table
 
df.pivot_table(values='D',index=['A', 'B'],columns=['C'],aggfunc="sum",fill_value =0,margins=True,,margins_name = "Grand Total")             #index is the rows required, columns is the required columns, 
                                                                                              #fill_value for the combinations not present in the data fill_value will replace with a dummy value
                                                                                               #margins = True (actually gives column totals and row totals
    table = pd.pivot_table(df,index=['Sex','Pclass'],aggfunc={'Age':np.mean,'Survived':np.sum})



# reading csv
df = pd.read_csv('example')

# writing to csv 
df.to_csv('example',index=False)

# reading excel
pd.read_excel('Excel_Sample.xlsx',sheetname='Sheet1')

# writing to excel
df.to_excel('Excel_Sample.xlsx',sheet_name='Sheet1')


#proc contents
df.info()

